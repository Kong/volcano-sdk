---
title: MCP Tools
description: The Model Context Protocol (MCP) enables AI agents to securely interact with external tools and data sources. Volcano SDK provides first-class MCP integration with automatic tool discovery, selection, and authentication.
---

# MCP Tools

The Model Context Protocol (MCP) enables AI agents to securely interact with external tools and data sources. Volcano SDK provides first-class MCP integration with automatic tool discovery, selection, and authentication.

:::note[What is MCP?]
The Model Context Protocol is an open standard for connecting AI systems to external data sources and tools. It enables LLMs to safely interact with databases, APIs, file systems, and other services through a unified interface.
:::

## Automatic Tool Selection

Let the LLM intelligently choose which tools to call based on the prompt. This is the recommended approach for most use cases.

```typescript
import { agent, llmOpenAI, mcp } from "volcano-sdk";

const weather = mcp("http://localhost:3000/mcp");
const notifications = mcp("http://localhost:4000/mcp");
const llm = llmOpenAI({ apiKey: process.env.OPENAI_API_KEY! });

await agent({ llm })
  .then({
    prompt: "Check SF weather for tomorrow and send me a notification.",
    mcps: [weather, notifications]
  })
  .run();

// The LLM automatically:
// 1. Discovers available tools from both servers
// 2. Selects the appropriate tools
// 3. Calls them with correct arguments
// 4. Returns the results
```

### How It Works

- **Tool Discovery:** Volcano fetches available tools from MCP servers (cached with TTL)
- **LLM Selection:** The LLM analyzes the prompt and chooses relevant tools
- **Schema Validation:** Arguments are validated against JSON Schema before execution
- **Iterative Calling:** The LLM can make multiple tool calls in sequence (default: 4 iterations)
- **Context Flow:** Tool results are automatically included in subsequent steps

### Controlling Tool Iterations

For complex tasks, the LLM may need multiple tool calls. Configure how many iterations are allowed:

```typescript
// Agent-level (default for all steps)
await agent({ 
  llm,
  maxToolIterations: 2  // Limit to 2 iterations (faster)
})
  .then({ prompt: "Task", mcps: [tools] })
  .run();

// Per-step override
await agent({ llm, maxToolIterations: 4 })  // Default 4
  .then({ 
    prompt: "Simple task",
    mcps: [tools],
    maxToolIterations: 1  // Fast: only 1 tool call
  })
  .then({ 
    prompt: "Complex task",
    mcps: [tools],
    maxToolIterations: 4  // More iterations for complexity
  })
  .run();
```

### Iteration Trade-offs

| maxToolIterations | Speed | Capability | Use Case |
|-------------------|-------|------------|----------|
| `1` | ‚ö° Fastest | Single tool call | Simple, direct tasks |
| `2` | üèÉ Fast | Tool + follow-up | Two-step operations |
| `4` (default) | ‚è±Ô∏è Moderate | Multi-step workflows | Complex orchestration |

:::tip[Performance tip]
Start with `maxToolIterations: 1` for simple tasks. Increase only if the LLM needs multiple tool calls to complete the task.
:::

### Multiple MCP Servers

Provide multiple MCP servers and the LLM will use tools from any of them:

```typescript
const database = mcp("http://localhost:5000/mcp");
const email = mcp("http://localhost:5001/mcp");
const analytics = mcp("http://localhost:5002/mcp");

await agent({ llm })
  .then({
    prompt: "Query user data, analyze it, and email the report to admin@example.com",
    mcps: [database, email, analytics]
  })
  .run();

// The LLM automatically orchestrates tools across all three servers
```

## Explicit Tool Calling

Call specific MCP tools directly when you know exactly which tool to use and with what arguments.

```typescript
const cafe = mcp("http://localhost:3000/mcp");

await agent({ llm })
  .then({ prompt: "Recommend a coffee for Ava from Naples" })
  .then({ 
    mcp: cafe, 
    tool: "order_item", 
    args: { item_id: "espresso", quantity: 2 } 
  })
  .run();
```

### With LLM Step

Combine LLM reasoning with explicit tool calls:

```typescript
await agent({ llm })
  .then({ 
    mcp: database,
    tool: "query_users",
    args: { status: "active" },
    prompt: "Analyze the results and summarize"  // LLM processes tool output
  })
  .run();
```

### When to Use Explicit Calling

- You know exactly which tool to call
- The arguments are predetermined
- You want fine-grained control over execution order
- You're building deterministic workflows

## MCP Authentication

Volcano SDK supports OAuth 2.1 and Bearer token authentication per the MCP specification. Authentication can be configured at the MCP handle level or centrally at the agent level.

### Handle-Level Authentication

Configure auth directly on the MCP handle:

```typescript
// OAuth on handle
const protectedMcp = mcp("https://api.example.com/mcp", {
  auth: {
    type: 'oauth',
    clientId: process.env.MCP_CLIENT_ID!,
    clientSecret: process.env.MCP_CLIENT_SECRET!,
    tokenEndpoint: 'https://api.example.com/oauth/token'
  }
});

// Bearer token on handle  
const bearerMcp = mcp("https://api.example.com/mcp", {
  auth: {
    type: 'bearer',
    token: process.env.MCP_BEARER_TOKEN!
  }
});
```

### Agent-Level Authentication

Configure auth centrally at the agent level for cleaner code when using multiple authenticated servers:

```typescript
// MCP handles without auth
const mcp1 = mcp("https://api.example.com/mcp");
const mcp2 = mcp("https://api.other.com/mcp");

// Auth configured at agent level
await agent({
  llm,
  mcpAuth: {
    'https://api.example.com/mcp': {
      type: 'oauth',
      clientId: process.env.CLIENT_ID_1!,
      clientSecret: process.env.CLIENT_SECRET_1!,
      tokenEndpoint: 'https://api.example.com/oauth/token'
    },
    'https://api.other.com/mcp': {
      type: 'bearer',
      token: process.env.TOKEN_2!
    }
  }
})
  .then({ prompt: "Use tools from both servers", mcps: [mcp1, mcp2] })
  .run();
```

:::tip[Precedence]
Handle-level auth takes precedence over agent-level auth. This allows you to set defaults at the agent level and override for specific handles.
:::

### OAuth Authentication (Client Credentials)

Recommended for production MCP servers. Volcano automatically acquires and refreshes tokens:

```typescript
const protectedMcp = mcp("https://api.example.com/mcp", {
  auth: {
    type: 'oauth',
    clientId: process.env.MCP_CLIENT_ID!,
    clientSecret: process.env.MCP_CLIENT_SECRET!,
    tokenEndpoint: 'https://api.example.com/oauth/token'
  }
});

await agent({ llm })
  .then({ 
    prompt: "Use protected tools",
    mcps: [protectedMcp]
  })
  .run();

// Volcano automatically:
// 1. Requests OAuth token from tokenEndpoint
// 2. Caches the token until expiration
// 3. Refreshes automatically when needed
// 4. Includes Authorization header in all requests
```

### Bearer Token Authentication

For pre-acquired tokens or custom authentication flows:

```typescript
const authMcp = mcp("https://api.example.com/mcp", {
  auth: {
    type: 'bearer',
    token: process.env.MCP_BEARER_TOKEN!
  }
});

await agent({ llm })
  .then({ mcp: authMcp, tool: "secure_action", args: {} })
  .run();
```

### Mixed Authentication

Combine authenticated and non-authenticated MCP servers in the same workflow:

```typescript
const publicMcp = mcp("http://localhost:3000/mcp");  // No auth
const privateMcp = mcp("https://api.example.com/mcp", {
  auth: {
    type: 'oauth',
    clientId: process.env.CLIENT_ID!,
    clientSecret: process.env.CLIENT_SECRET!,
    tokenEndpoint: 'https://api.example.com/oauth/token'
  }
});

await agent({ llm })
  .then({ mcp: publicMcp, tool: "get_public_data", args: {} })
  .then({ mcp: privateMcp, tool: "store_private_data", args: {} })
  .run();

// Each server uses its own authentication (or none)
```

:::note[MCP Spec Compliance]
Per the official MCP specification, servers use OAuth 2.1 for authentication. Volcano supports both OAuth (automatic token acquisition) and Bearer (bring your own token).
:::

### Authentication Features

- **OAuth token caching:** Tokens are cached and reused until expiration (60s buffer)
- **Automatic refresh:** Expired tokens are refreshed automatically
- **Per-endpoint configuration:** Each MCP server can have different auth
- **Connection pooling:** Authenticated connections are pooled separately
- **Spec compliant:** Follows MCP OAuth 2.1 authentication standard

## Connection Pooling & Performance

Volcano SDK automatically manages MCP connections for optimal performance.

### Connection Pooling

- **Automatic pooling:** TCP sessions are reused across steps
- **LRU eviction:** Idle connections evicted when pool is full
- **Per-endpoint pools:** Each MCP server has its own pool
- **Auth-aware:** Authenticated connections pooled separately
- **Configurable limits:** Max 16 connections, 30s idle timeout (default)

### Tool Discovery Cache

- **Cached with TTL:** `listTools()` results cached for 60s
- **Per-endpoint cache:** Each MCP server cached independently
- **Invalidation on failure:** Cache cleared if server becomes unavailable
- **Reduced latency:** Subsequent requests use cached tool definitions

### Schema Validation

Tool arguments are validated against JSON Schema before execution:

```typescript
// If the MCP tool has this schema:
{
  "type": "object",
  "properties": {
    "city": { "type": "string" },
    "units": { "type": "string", "enum": ["celsius", "fahrenheit"] }
  },
  "required": ["city"]
}

// This call would fail validation:
await agent({ llm })
  .then({ 
    mcp: weather, 
    tool: "get_weather", 
    args: { units: "kelvin" }  // ‚ùå Missing required "city", invalid enum
  })
  .run();

// Error: ValidationError
// Message: "arguments failed schema validation: city is required; units must be one of..."
```

### Configuration

Advanced configuration for testing or special scenarios:

```typescript
import { 
  __internal_setPoolConfig,
  __internal_setDiscoveryTtl,
  __internal_clearDiscoveryCache,
  __internal_clearOAuthTokenCache
} from "volcano-sdk";

// Configure connection pool
__internal_setPoolConfig(32, 60_000); // max 32 connections, 60s idle

// Configure tool discovery cache TTL
__internal_setDiscoveryTtl(120_000); // 120s cache

// Clear caches (useful for testing)
__internal_clearDiscoveryCache();
__internal_clearOAuthTokenCache();
```

:::warning[Note]
These are internal APIs for advanced use cases and testing. The default configuration works well for most applications.
:::