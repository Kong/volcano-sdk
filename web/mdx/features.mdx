---
title: Features
description: Core features for building AI agents - execution methods, streaming, retries, timeouts, hooks, error handling, and MCP tool integration.
---

# Features

Core features for building AI agents: execution methods, streaming, retries, timeouts, hooks, error handling, and MCP tool integration.

## run() Method

Execute the complete agent workflow and return all step results at once.

```typescript
const results = await agent({ llm })
  .then({ prompt: "Analyze user data", mcps: [analytics] })
  .then({ prompt: "Generate insights" })
  .then({ prompt: "Create recommendations" })
  .run();

// All steps complete before results are returned
console.log(results); // Array of all StepResult objects
console.log(results[0].llmOutput); // First step output
console.log(results[1].llmOutput); // Second step output
console.log(results[results.length - 1].totalDurationMs); // Total time
```

### With Logging Callback

Pass a callback function to log each step as it completes:

```typescript
const results = await agent({ llm })
  .then({ prompt: "Step 1" })
  .then({ prompt: "Step 2" })
  .then({ prompt: "Step 3" })
  .run((stepResult, stepIndex) => {
    console.log(`Step ${stepIndex + 1} completed`);
    console.log(`Duration: ${stepResult.durationMs}ms`);
    console.log(`Output: ${stepResult.llmOutput}`);
  });

// Callback is called for each step as it completes
// Final results array is returned when all steps finish
```

### Return Value

Returns `Promise<StepResult[]>` with all step results:

```typescript
type StepResult = {
  prompt?: string;
  llmOutput?: string;
  durationMs?: number;
  llmMs?: number;
  toolCalls?: Array<{ name: string; result: any; ms?: number }>;
  // Aggregated metrics (on final step only):
  totalDurationMs?: number;
  totalLlmMs?: number;
  totalMcpMs?: number;
};
```

### Characteristics

- **Waits for completion:** Returns only after all steps finish
- **Aggregated metrics:** Final step includes total duration, LLM time, and MCP time
- **Error handling:** Throws on first failure (use try/catch)
- **Sequential execution:** Steps run in order, one after another
- **Full results:** Access all step data for analysis or debugging

### When to Use run()

- Batch processing where you need complete results
- Scripts that can wait for full completion
- Analysis workflows needing aggregated metrics
- APIs returning complete responses
- Testing and debugging (inspect all steps together)

## stream() Method

Stream step results in real-time as they complete using the `stream()` method.

```typescript
for await (const stepResult of agent({ llm })
  .then({ prompt: "Analyze user data", mcps: [analytics] })
  .then({ prompt: "Generate insights" })
  .then({ prompt: "Create recommendations" })
  .stream()) {
  
  console.log(`Step completed: ${stepResult.prompt}`);
  console.log(`Duration: ${stepResult.durationMs}ms`);
  
  if (stepResult.llmOutput) {
    console.log(`Result: ${stepResult.llmOutput}`);
  }
}
```

### Streaming with Progress Tracking

```typescript
let completedSteps = 0;
const totalSteps = 3;

for await (const stepResult of workflow.stream((step, stepIndex) => {
  completedSteps++;
  console.log(`Progress: ${completedSteps}/${totalSteps}`);
})) {
  updateProgressBar(completedSteps / totalSteps);
  displayStepResult(stepResult);
}
```

### When to Use Streaming

| Use `stream()` for: | Use `run()` for: |
|---------------------|------------------|
| Interactive applications needing live updates | Batch processing |
| Long-running workflows (>5 seconds) | Simple scripts |
| Real-time dashboards | Analysis workflows |
| WebSocket/SSE applications | APIs returning complete responses |
| Memory-sensitive environments | Testing and debugging |
| Early termination scenarios | When you need aggregated metrics |

### Characteristics

- **Immediate feedback:** First result available when first step completes
- **Memory efficient:** Results can be processed and discarded incrementally
- **Progressive display:** Results appear as they complete
- **Same execution model:** Retries, timeouts, and validation work identically to `run()`

## Retries & Timeouts

### Timeouts

Set per-step or global timeouts (in seconds):

```typescript
await agent({ llm, timeout: 60 })
  .then({ prompt: "Quick check", timeout: 5 })  // Override to 5s
  .then({ prompt: "Next step uses agent default (60s)" })
  .run();
```

### Retry Strategies

#### Immediate Retry (Default)

Retry immediately without waiting:

```typescript
await agent({ llm, retry: { retries: 3 } })
  .then({ prompt: "hello" })
  .run();
```

#### Delayed Retry

Wait a fixed duration between attempts:

```typescript
await agent({ llm, retry: { delay: 20, retries: 3 } })
  .then({ prompt: "unstable action" })
  .run();
// Waits 20s between each retry
```

#### Exponential Backoff

Progressively longer waits between retries:

```typescript
await agent({ llm, retry: { backoff: 2, retries: 4 } })
  .then({ prompt: "might fail" })
  .run();
// Waits: 1s, 2s, 4s, 8s between attempts
```

### Per-Step Override

```typescript
await agent({ llm, retry: { delay: 20 } })
  .then({ prompt: "override to immediate", retry: { delay: 0 } })
  .run();
```

### Retry Semantics

- Non-retryable errors (like `ValidationError`) abort immediately
- Retryable errors include: timeouts, 429, 5xx, network errors
- On retry exhaustion, the last error is thrown
- You cannot set both `delay` and `backoff`

## Step Hooks

Add `pre` and `post` hooks for fine-grained control over execution flow:

```typescript
await agent({ llm })
  .then({
    prompt: "Analyze the user data",
    mcps: [analytics],
    pre: () => { console.log("Starting analysis..."); },
    post: () => { console.log("Analysis complete!"); }
  })
  .then({
    prompt: "Generate report",
    pre: () => { startTimer(); },
    post: () => { endTimer(); saveMetrics(); }
  })
  .run((step, stepIndex) => {
    console.log(`Step ${stepIndex + 1} finished`);
  });
```

### Hook Execution Order

1. `pre()` hook (before step execution)
2. Step execution (LLM/MCP calls)
3. `post()` hook (after step completion)
4. `run()` callback (with step result and index)

### Hook Characteristics

- Hooks are **synchronous functions** (`() => void`)
- Hook errors are **caught and logged** but don't fail the step
- Hooks execute on **every retry attempt** (pre) or **only on success** (post)
- Hooks have access to **closure variables** for state management

:::warning[Note]
Hook errors are caught and logged but do not fail the step. Pre-hooks execute on every retry attempt. Post-hooks execute only on successful completion.
:::

### Use Cases

- Performance monitoring and timing
- Logging and debugging
- State management
- Notifications and alerts
- Metrics collection

## Error Handling

Volcano surfaces typed errors with rich metadata for easy debugging.

### Error Types

| Error Type | Description |
|------------|-------------|
| `AgentConcurrencyError` | run() called twice on same instance |
| `TimeoutError` | Step exceeded timeout limit |
| `ValidationError` | Tool args failed schema validation |
| `RetryExhaustedError` | Final failure after all retries |
| `LLMError` | LLM provider error |
| `MCPToolError` | MCP tool execution error |
| `MCPConnectionError` | MCP connection error |

### Error Metadata

All Volcano errors include metadata for debugging:

```typescript
try {
  await agent({ llm, retry: { backoff: 2, retries: 4 }, timeout: 30 })
    .then({ prompt: 'auto', mcps: [mcp('http://localhost:3211/mcp')] })
    .run();
} catch (err) {
  if (err && typeof err === 'object' && 'meta' in err) {
    const e = err as VolcanoError;
    
    console.error(e.name, e.message);
    console.error('Metadata:', {
      stepId: e.meta.stepId,        // 0-based step index
      provider: e.meta.provider,     // llm:openai or mcp:localhost
      requestId: e.meta.requestId,   // Upstream request ID
      retryable: e.meta.retryable    // Should retry?
    });
    
    if (e.meta?.retryable) {
      // Maybe enqueue for retry later
    }
  }
}
```

### Metadata Fields

- `stepId`: 0-based index of the failing step
- `provider`: `llm:<id|model>` or `mcp:<host>`
- `requestId`: Upstream provider request ID when available
- `retryable`: Volcano's hint (true for 429/5xx/timeouts; false for validation/4xx)