<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Observability - Volcano SDK</title>
  <link rel="stylesheet" href="styles.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet" media="print" onload="this.media='all'">
  <noscript><link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet"></noscript>
  <link rel="stylesheet" href="https://unpkg.com/prismjs@1.29.0/themes/prism-tomorrow.min.css"/>
  <script src="https://unpkg.com/prismjs@1.29.0/components/prism-core.min.js"></script>
  <script src="https://unpkg.com/prismjs@1.29.0/components/prism-clike.min.js"></script>
  <script src="https://unpkg.com/prismjs@1.29.0/components/prism-javascript.min.js"></script>
  <script src="https://unpkg.com/prismjs@1.29.0/components/prism-typescript.min.js"></script>
  <script src="https://unpkg.com/prismjs@1.29.0/components/prism-bash.min.js"></script>
</head>
<body>
  <div class="layout">
    <!-- Sidebar Navigation -->
    <aside class="sidebar">
      <div class="sidebar-header">
        <a href="index.html" class="logo">
          <span class="emoji">üåã</span>
          <span class="text">Volcano SDK</span>
        </a>
      </div>
      
      <nav class="sidebar-nav">
        <div class="nav-section">
          <div class="nav-section-title">Getting Started</div>
          <a href="index.html#introduction" class="nav-link">Introduction</a>
          <a href="index.html#installation" class="nav-link">Installation</a>
          <a href="index.html#quick-start" class="nav-link">Quick Start</a>
          <a href="index.html#use-cases" class="nav-link">Use Cases</a>
          <a href="index.html#comparison" class="nav-link">Volcano vs Others</a>
          <a href="index.html#core-concepts" class="nav-link">Core Concepts</a>
          <a href="examples.html" class="nav-link">Examples</a>
          <a href="index.html#questions" class="nav-link">Questions & Requests</a>
        </div>

        <div class="nav-section">
          <div class="nav-section-title">Providers</div>
          <a href="providers.html" class="nav-link">Overview</a>
          <a href="providers.html#openai" class="nav-link">OpenAI</a>
          <a href="providers.html#anthropic" class="nav-link">Anthropic (Claude)</a>
          <a href="providers.html#mistral" class="nav-link">Mistral</a>
          <a href="providers.html#llama" class="nav-link">Llama</a>
          <a href="providers.html#bedrock" class="nav-link">AWS Bedrock</a>
          <a href="providers.html#vertex" class="nav-link">Google Vertex Studio</a>
          <a href="providers.html#azure" class="nav-link">Azure AI</a>
          <a href="providers.html#custom" class="nav-link">Custom Provider</a>
        </div>

        <div class="nav-section">
          <div class="nav-section-title">MCP Tools</div>
          <a href="mcp-tools.html" class="nav-link">Overview</a>
          <a href="mcp-tools.html#automatic" class="nav-link">Automatic Selection</a>
          <a href="mcp-tools.html#explicit" class="nav-link">Explicit Calling</a>
          <a href="mcp-tools.html#authentication" class="nav-link">Authentication</a>
          <a href="mcp-tools.html#connection-pooling" class="nav-link">Connection Pooling</a>
        </div>

        <div class="nav-section">
          <div class="nav-section-title">Advanced Patterns</div>
          <a href="patterns.html" class="nav-link">Overview</a>
          <a href="patterns.html#multi-llm" class="nav-link">Multi-LLM Workflows</a>
          <a href="patterns.html#parallel" class="nav-link">Parallel Execution</a>
          <a href="patterns.html#branching" class="nav-link">Conditional Branching</a>
          <a href="patterns.html#loops" class="nav-link">Loops</a>
          <a href="patterns.html#sub-agents" class="nav-link">Sub-Agent Composition</a>
        </div>

        <div class="nav-section">
          <div class="nav-section-title">Features</div>
          <a href="features.html" class="nav-link">Overview</a>
          <a href="features.html#run" class="nav-link">run() Method</a>
          <a href="features.html#streaming" class="nav-link">stream() Method</a>
          <a href="features.html#retries" class="nav-link">Retries & Timeouts</a>
          <a href="features.html#hooks" class="nav-link">Step Hooks</a>
          <a href="features.html#errors" class="nav-link">Error Handling</a>
        </div>

        <div class="nav-section">
          <div class="nav-section-title">Observability</div>
          <a href="observability.html" class="nav-link active">Overview</a>
          <a href="#opentelemetry" class="nav-link">OpenTelemetry</a>
          <a href="#traces" class="nav-link">Distributed Tracing</a>
          <a href="#metrics" class="nav-link">Metrics</a>
          <a href="#backends" class="nav-link">Observability Backends</a>
        </div>

        <div class="nav-section">
          <div class="nav-section-title">API Reference</div>
          <a href="api.html" class="nav-link">Overview</a>
          <a href="api.html#agent" class="nav-link">agent()</a>
          <a href="api.html#step" class="nav-link">Step Types</a>
          <a href="api.html#results" class="nav-link">Step Results</a>
        </div>
      </nav>
    </aside>

    <!-- Main Content -->
    <main class="content">
      <div class="content-inner">
        <section class="doc-section">
          <h1>Observability</h1>
          <p class="lead">Production-ready observability with OpenTelemetry traces and metrics. Monitor agent performance, debug failures, and optimize costs. Opt-in and fully optional.</p>
          
          <div class="highlight-box blue">
            <strong>Opt-In by Design:</strong> Observability is disabled by default. Enable it by configuring telemetry when creating your agent. No performance impact when disabled.
          </div>
        </section>

        <!-- OpenTelemetry -->
        <section id="opentelemetry" class="doc-section">
          <h2>OpenTelemetry Integration</h2>
          <p>Volcano SDK uses OpenTelemetry (OTEL), the industry-standard observability framework. Export traces and metrics to any OTEL-compatible backend.</p>
          
          <h3>Quick Start</h3>
          <p><strong>Step 1:</strong> Configure OpenTelemetry SDK (one-time setup):</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">// app.ts or index.ts - run once at startup
import { NodeSDK } from '@opentelemetry/sdk-node';
import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';

// Configure OTEL to send to your observability backend
const sdk = new NodeSDK({
  serviceName: 'my-agent-service',
  traceExporter: new OTLPTraceExporter({
    url: 'http://localhost:4318/v1/traces',  // Your OTEL collector
    // For production: configure your observability backend URL
    // url: process.env.OTEL_EXPORTER_OTLP_ENDPOINT
    // headers: { 'Authorization': `Bearer ${process.env.API_KEY}` }
  })
});

sdk.start();

// Optional: Graceful shutdown
process.on('SIGTERM', async () => {
  await sdk.shutdown();
});</code></pre>
          </div>

          <p><strong>Step 2:</strong> Enable telemetry in your agents:</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">import { agent, llmOpenAI, createVolcanoTelemetry } from "volcano-sdk";

// Create telemetry (uses global OTEL SDK configured above)
const telemetry = createVolcanoTelemetry({
  serviceName: 'my-agent-service'
});

// Pass to agent
const results = await agent({ 
  llm: llmOpenAI({ apiKey: process.env.OPENAI_API_KEY! }),
  telemetry  // Enable observability
})
  .then({ prompt: "Analyze data" })
  .then({ prompt: "Generate report" })
  .run();

// Traces and metrics automatically sent to your configured backend!</code></pre>
          </div>

          <div class="info-box success">
            <div class="info-icon">‚úì</div>
            <div>
              <strong>That's it!</strong> Volcano spans and metrics are now being sent to your observability backend. View them in Jaeger, Grafana, DataDog, NewRelic, or any OTEL-compatible system.
            </div>
          </div>

          <h3>Installation</h3>
          <p>Install the OpenTelemetry API (peer dependency):</p>
          
          <div class="code-block">
            <pre><code class="language-bash"># Required for telemetry
npm install @opentelemetry/api

# Optional: SDK and exporters for backends
npm install @opentelemetry/sdk-node
npm install @opentelemetry/exporter-jaeger
npm install @opentelemetry/exporter-prometheus
npm install @opentelemetry/exporter-otlp-http</code></pre>
          </div>

          <div class="info-box">
            <div class="info-icon">‚ÑπÔ∏è</div>
            <div>
              <strong>Optional Dependency:</strong> If <code>@opentelemetry/api</code> is not installed, telemetry becomes a no-op. Your code works normally without observability.
            </div>
          </div>
        </section>

        <!-- Distributed Tracing -->
        <section id="traces" class="doc-section">
          <h2>Distributed Tracing</h2>
          <p>Volcano creates hierarchical traces showing the complete execution flow of your agent workflows.</p>
          
          <h3>Trace Hierarchy</h3>
          <div class="code-block">
            <pre><code class="language-text">Trace: agent-run-abc123
‚îú‚îÄ‚îÄ Span: agent.run (parent)
‚îÇ   ‚îú‚îÄ‚îÄ Span: step[0].execute (type: mcp_auto)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Span: llm.generate (provider: openai, model: gpt-4o-mini)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Span: mcp.discover_tools (endpoint: http://...)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Span: mcp.call_tool (tool: get_weather)
‚îÇ   ‚îú‚îÄ‚îÄ Span: step[1].execute (type: llm)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Span: llm.generate (provider: anthropic, model: claude-3-haiku)
‚îÇ   ‚îî‚îÄ‚îÄ Span: step[2].execute (type: mcp_explicit)
‚îÇ       ‚îî‚îÄ‚îÄ Span: mcp.call_tool (tool: send_notification)</code></pre>
          </div>

          <h3>Span Attributes</h3>
          <p>Each span includes rich attributes for debugging:</p>
          
          <table class="params-table">
            <thead>
              <tr>
                <th>Span Type</th>
                <th>Attributes</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>agent.run</strong></td>
                <td><code>agent.step_count</code>, <code>volcano.version</code></td>
              </tr>
              <tr>
                <td><strong>step.execute</strong></td>
                <td><code>step.index</code>, <code>step.type</code> (llm | mcp_auto | mcp_explicit)</td>
              </tr>
              <tr>
                <td><strong>llm.generate</strong></td>
                <td><code>llm.provider</code>, <code>llm.model</code>, <code>llm.prompt_length</code></td>
              </tr>
              <tr>
                <td><strong>mcp.*</strong></td>
                <td><code>mcp.endpoint</code>, <code>mcp.operation</code>, <code>mcp.has_auth</code></td>
              </tr>
            </tbody>
          </table>

          <h3>Error Tracking</h3>
          <p>When errors occur, spans include exception details:</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">// Errors are automatically recorded in spans
try {
  await agent({ llm, telemetry })
    .then({ prompt: "This might fail" })
    .run();
} catch (error) {
  // Span will have:
  // - status: ERROR
  // - exception details
  // - stack trace
}</code></pre>
          </div>
        </section>

        <!-- Metrics -->
        <section id="metrics" class="doc-section">
          <h2>Metrics</h2>
          <p>Volcano records metrics for dashboards and alerting.</p>
          
          <h3>Available Metrics</h3>
          <table class="params-table">
            <thead>
              <tr>
                <th>Metric</th>
                <th>Type</th>
                <th>Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><code>volcano.agent.duration</code></td>
                <td>Histogram</td>
                <td>Total agent execution time (ms)</td>
              </tr>
              <tr>
                <td><code>volcano.step.duration</code></td>
                <td>Histogram</td>
                <td>Individual step duration (ms), labeled by type</td>
              </tr>
              <tr>
                <td><code>volcano.llm.calls.total</code></td>
                <td>Counter</td>
                <td>Total LLM API calls, labeled by provider and error status</td>
              </tr>
              <tr>
                <td><code>volcano.mcp.calls.total</code></td>
                <td>Counter</td>
                <td>Total MCP tool calls</td>
              </tr>
              <tr>
                <td><code>volcano.errors.total</code></td>
                <td>Counter</td>
                <td>Total errors by type and provider</td>
              </tr>
            </tbody>
          </table>

          <h3>Metric Labels</h3>
          <p>Metrics include labels for filtering and grouping:</p>
          <ul>
            <li><code>provider</code> - LLM provider (openai, anthropic, etc.)</li>
            <li><code>model</code> - Specific model used</li>
            <li><code>type</code> - Step type (llm, mcp_auto, mcp_explicit)</li>
            <li><code>error</code> - Boolean indicating success/failure</li>
          </ul>
        </section>

        <!-- Observability Backends -->
        <section id="backends" class="doc-section">
          <h2>Observability Backends</h2>
          <p>Volcano works with any OpenTelemetry-compatible backend.</p>
          
          <h3>Jaeger (Distributed Tracing)</h3>
          <div class="code-block">
            <pre><code class="language-typescript">import { NodeSDK } from '@opentelemetry/sdk-node';
import { JaegerExporter } from '@opentelemetry/exporter-jaeger';
import { createVolcanoTelemetry } from 'volcano-sdk';

// Setup OTEL SDK
const sdk = new NodeSDK({
  serviceName: 'my-agent',
  traceExporter: new JaegerExporter({
    endpoint: 'http://localhost:14268/api/traces'
  })
});

sdk.start();

// Use with Volcano
const telemetry = createVolcanoTelemetry({
  serviceName: 'my-agent'
});

await agent({ llm, telemetry })
  .then({ prompt: "..." })
  .run();

// View traces in Jaeger UI at http://localhost:16686</code></pre>
          </div>

          <h3>Prometheus (Metrics)</h3>
          <div class="code-block">
            <pre><code class="language-typescript">import { NodeSDK } from '@opentelemetry/sdk-node';
import { PrometheusExporter } from '@opentelemetry/exporter-prometheus';

const prometheusExporter = new PrometheusExporter({
  port: 9464
});

const sdk = new NodeSDK({
  serviceName: 'my-agent',
  metricReader: prometheusExporter
});

sdk.start();

// Metrics available at http://localhost:9464/metrics
// volcano_agent_duration_bucket{le="100"} 42
// volcano_llm_calls_total{provider="openai"} 156</code></pre>
          </div>

          <h3>DataDog / NewRelic / Grafana Cloud</h3>
          <div class="code-block">
            <pre><code class="language-typescript">import { OTLPTraceExporter } from '@opentelemetry/exporter-otlp-http';
import { NodeSDK } from '@opentelemetry/sdk-node';

const sdk = new NodeSDK({
  serviceName: 'my-agent',
  traceExporter: new OTLPTraceExporter({
    url: process.env.OTEL_EXPORTER_OTLP_ENDPOINT,
    headers: {
      'DD-API-KEY': process.env.DD_API_KEY  // DataDog
      // or 'X-License-Key': process.env.NEW_RELIC_KEY
      // or 'Authorization': `Bearer ${process.env.GRAFANA_TOKEN}`
    }
  })
});

sdk.start();</code></pre>
          </div>

          <h3>Environment Variables</h3>
          <p>OTEL supports standard environment variables for configuration:</p>
          
          <div class="code-block">
            <pre><code class="language-bash"># OTLP endpoint (your observability backend)
export OTEL_EXPORTER_OTLP_ENDPOINT="http://localhost:4318"

# Service name
export OTEL_SERVICE_NAME="my-agent"

# Headers (API keys, etc.)
export OTEL_EXPORTER_OTLP_HEADERS="Authorization=Bearer your-api-key"

# Traces only, metrics only, or both
export OTEL_TRACES_EXPORTER="otlp"
export OTEL_METRICS_EXPORTER="otlp"</code></pre>
          </div>
        </section>

        <!-- Advanced Configuration -->
        <section id="advanced" class="doc-section">
          <h2>Advanced Configuration</h2>
          
          <h3>Custom Tracer and Meter</h3>
          <p>Provide your own OTEL tracer and meter instances:</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">import { trace, metrics } from '@opentelemetry/api';
import { createVolcanoTelemetry } from 'volcano-sdk';

const tracer = trace.getTracer('my-custom-tracer');
const meter = metrics.getMeter('my-custom-meter');

const telemetry = createVolcanoTelemetry({
  serviceName: 'my-agent',
  tracer,
  meter
});</code></pre>
          </div>

          <h3>Disable Traces or Metrics</h3>
          <div class="code-block">
            <pre><code class="language-typescript">// Only traces, no metrics
const telemetry = createVolcanoTelemetry({
  serviceName: 'my-agent',
  traces: true,
  metrics: false
});

// Only metrics, no traces
const telemetry = createVolcanoTelemetry({
  serviceName: 'my-agent',
  traces: false,
  metrics: true
});</code></pre>
          </div>
        </section>

        <!-- Best Practices -->
        <section id="best-practices" class="doc-section">
          <h2>Best Practices</h2>
          
          <ul class="benefits-list">
            <li><strong>Production only:</strong> Enable telemetry in production, disable in development for faster iteration</li>
            <li><strong>Sampling:</strong> Use OTEL sampling for high-traffic applications to reduce costs</li>
            <li><strong>Service naming:</strong> Use descriptive service names for easier filtering</li>
            <li><strong>Label cardinality:</strong> Be mindful of high-cardinality labels (user IDs, etc.)</li>
            <li><strong>Monitor costs:</strong> Observability backends charge by data volume - sample appropriately</li>
          </ul>

          <div class="info-box warning">
            <div class="info-icon">‚ö†Ô∏è</div>
            <div>
              <strong>Performance:</strong> Telemetry adds minimal overhead (~1-5ms per workflow) but can increase network traffic to your observability backend. Use sampling for high-throughput applications.
            </div>
          </div>
        </section>

      </div>

      <!-- Table of Contents (Right Sidebar) -->
      <aside class="toc">
        <div class="toc-header">On this page</div>
        <nav class="toc-nav" id="toc-nav">
          <!-- Dynamically populated by script.js -->
        </nav>
      </aside>
    </main>
  </div>

  <script src="script.js"></script>
</body>
</html>
