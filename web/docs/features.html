<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Features - Volcano SDK</title>
  <link rel="stylesheet" href="styles.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet" media="print" onload="this.media='all'">
  <noscript><link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet"></noscript>
  <link rel="stylesheet" href="https://unpkg.com/prismjs@1.29.0/themes/prism-tomorrow.min.css"/>
  <script src="https://unpkg.com/prismjs@1.29.0/components/prism-core.min.js"></script>
  <script src="https://unpkg.com/prismjs@1.29.0/components/prism-clike.min.js"></script>
  <script src="https://unpkg.com/prismjs@1.29.0/components/prism-javascript.min.js"></script>
  <script src="https://unpkg.com/prismjs@1.29.0/components/prism-typescript.min.js"></script>
  <script src="https://unpkg.com/prismjs@1.29.0/components/prism-bash.min.js"></script>
</head>
<body>
  <div class="layout">
    <!-- Sidebar Navigation -->
    <aside class="sidebar">
      <div class="sidebar-header">
        <a href="index.html" class="logo">
          <span class="emoji">🌋</span>
          <span class="text">Volcano SDK</span>
        </a>
      </div>
      
      <nav class="sidebar-nav">
        <div class="nav-section">
          <div class="nav-section-title">Getting Started</div>
          <a href="index.html#introduction" class="nav-link">Introduction</a>
          <a href="index.html#installation" class="nav-link">Installation</a>
          <a href="index.html#quick-start" class="nav-link">Quick Start</a>
          <a href="index.html#use-cases" class="nav-link">Use Cases</a>
          <a href="index.html#comparison" class="nav-link">Volcano vs Others</a>
          <a href="index.html#core-concepts" class="nav-link">Core Concepts</a>
          <a href="examples.html" class="nav-link">Examples</a>
        </div>

        <div class="nav-section">
          <div class="nav-section-title">Providers</div>
          <a href="providers.html" class="nav-link">Overview</a>
          <a href="providers.html#openai" class="nav-link">OpenAI</a>
          <a href="providers.html#anthropic" class="nav-link">Anthropic (Claude)</a>
          <a href="providers.html#mistral" class="nav-link">Mistral</a>
          <a href="providers.html#llama" class="nav-link">Llama</a>
          <a href="providers.html#bedrock" class="nav-link">AWS Bedrock</a>
          <a href="providers.html#vertex" class="nav-link">Google Vertex Studio</a>
          <a href="providers.html#azure" class="nav-link">Azure AI</a>
          <a href="providers.html#custom" class="nav-link">Custom Provider</a>
        </div>

        <div class="nav-section">
          <div class="nav-section-title">Advanced Patterns</div>
          <a href="patterns.html" class="nav-link">Overview</a>
          <a href="patterns.html#parallel" class="nav-link">Parallel Execution</a>
          <a href="patterns.html#branching" class="nav-link">Conditional Branching</a>
          <a href="patterns.html#loops" class="nav-link">Loops</a>
          <a href="patterns.html#sub-agents" class="nav-link">Sub-Agent Composition</a>
        </div>

        <div class="nav-section">
          <div class="nav-section-title">Features</div>
          <a href="features.html" class="nav-link active">Overview</a>
          <a href="#run" class="nav-link">run() Method</a>
          <a href="#streaming" class="nav-link">stream() Method</a>
          <a href="#retries" class="nav-link">Retries & Timeouts</a>
          <a href="#hooks" class="nav-link">Step Hooks</a>
          <a href="#errors" class="nav-link">Error Handling</a>
          <a href="#mcp-tools" class="nav-link">MCP Tools</a>
        </div>

        <div class="nav-section">
          <div class="nav-section-title">API Reference</div>
          <a href="api.html" class="nav-link">Overview</a>
          <a href="api.html#agent" class="nav-link">agent()</a>
          <a href="api.html#step" class="nav-link">Step Types</a>
          <a href="api.html#results" class="nav-link">Step Results</a>
        </div>
      </nav>
    </aside>

    <!-- Main Content -->
    <main class="content">
      <div class="content-inner">
        <section class="doc-section">
          <h1>Features</h1>
          <p class="lead">Core features for building AI agents: execution methods, streaming, retries, timeouts, hooks, error handling, and MCP tool integration.</p>
        </section>

        <!-- run() Method -->
        <section id="run" class="doc-section">
          <h2>run() Method</h2>
          <p>Execute the complete agent workflow and return all step results at once.</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">const results = await agent({ llm })
  .then({ prompt: "Analyze user data", mcps: [analytics] })
  .then({ prompt: "Generate insights" })
  .then({ prompt: "Create recommendations" })
  .run();

// All steps complete before results are returned
console.log(results); // Array of all StepResult objects
console.log(results[0].llmOutput); // First step output
console.log(results[1].llmOutput); // Second step output
console.log(results[results.length - 1].totalDurationMs); // Total time</code></pre>
          </div>

          <h3>With Logging Callback</h3>
          <p>Pass a callback function to log each step as it completes:</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">const results = await agent({ llm })
  .then({ prompt: "Step 1" })
  .then({ prompt: "Step 2" })
  .then({ prompt: "Step 3" })
  .run((stepResult, stepIndex) => {
    console.log(`Step ${stepIndex + 1} completed`);
    console.log(`Duration: ${stepResult.durationMs}ms`);
    console.log(`Output: ${stepResult.llmOutput}`);
  });

// Callback is called for each step as it completes
// Final results array is returned when all steps finish</code></pre>
          </div>

          <h3>Return Value</h3>
          <p>Returns <code>Promise&lt;StepResult[]&gt;</code> with all step results:</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">type StepResult = {
  prompt?: string;
  llmOutput?: string;
  durationMs?: number;
  llmMs?: number;
  toolCalls?: Array<{ name: string; result: any; ms?: number }>;
  // Aggregated metrics (on final step only):
  totalDurationMs?: number;
  totalLlmMs?: number;
  totalMcpMs?: number;
};</code></pre>
          </div>

          <h3>Characteristics</h3>
          <ul class="benefits-list">
            <li><strong>Waits for completion:</strong> Returns only after all steps finish</li>
            <li><strong>Aggregated metrics:</strong> Final step includes total duration, LLM time, and MCP time</li>
            <li><strong>Error handling:</strong> Throws on first failure (use try/catch)</li>
            <li><strong>Sequential execution:</strong> Steps run in order, one after another</li>
            <li><strong>Full results:</strong> Access all step data for analysis or debugging</li>
          </ul>

          <h3>When to Use run()</h3>
          <ul>
            <li>Batch processing where you need complete results</li>
            <li>Scripts that can wait for full completion</li>
            <li>Analysis workflows needing aggregated metrics</li>
            <li>APIs returning complete responses</li>
            <li>Testing and debugging (inspect all steps together)</li>
          </ul>
        </section>

        <!-- Streaming -->
        <section id="streaming" class="doc-section">
          <h2>stream() Method</h2>
          <p>Stream step results in real-time as they complete using the <code>stream()</code> method.</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">for await (const stepResult of agent({ llm })
  .then({ prompt: "Analyze user data", mcps: [analytics] })
  .then({ prompt: "Generate insights" })
  .then({ prompt: "Create recommendations" })
  .stream()) {
  
  console.log(`Step completed: ${stepResult.prompt}`);
  console.log(`Duration: ${stepResult.durationMs}ms`);
  
  if (stepResult.llmOutput) {
    console.log(`Result: ${stepResult.llmOutput}`);
  }
}</code></pre>
          </div>

          <h3>Streaming with Progress Tracking</h3>
          <div class="code-block">
            <pre><code class="language-typescript">let completedSteps = 0;
const totalSteps = 3;

for await (const stepResult of workflow.stream((step, stepIndex) => {
  completedSteps++;
  console.log(`Progress: ${completedSteps}/${totalSteps}`);
})) {
  updateProgressBar(completedSteps / totalSteps);
  displayStepResult(stepResult);
}</code></pre>
          </div>

          <h3>When to Use Streaming</h3>
          <div class="comparison-table">
            <div class="comparison-column">
              <h4>Use <code>stream()</code> for:</h4>
              <ul>
                <li>Interactive applications needing live updates</li>
                <li>Long-running workflows (&gt;5 seconds)</li>
                <li>Real-time dashboards</li>
                <li>WebSocket/SSE applications</li>
                <li>Memory-sensitive environments</li>
                <li>Early termination scenarios</li>
              </ul>
            </div>
            <div class="comparison-column">
              <h4>Use <code>run()</code> for:</h4>
              <ul>
                <li>Batch processing</li>
                <li>Simple scripts</li>
                <li>Analysis workflows</li>
                <li>APIs returning complete responses</li>
                <li>Testing and debugging</li>
                <li>When you need aggregated metrics</li>
              </ul>
            </div>
          </div>

          <h3>Characteristics</h3>
          <ul>
            <li><strong>Immediate feedback:</strong> First result available when first step completes</li>
            <li><strong>Memory efficient:</strong> Results can be processed and discarded incrementally</li>
            <li><strong>Progressive display:</strong> Results appear as they complete</li>
            <li><strong>Same execution model:</strong> Retries, timeouts, and validation work identically to <code>run()</code></li>
          </ul>
        </section>

        <!-- Retries & Timeouts -->
        <section id="retries" class="doc-section">
          <h2>Retries & Timeouts</h2>
          
          <h3>Timeouts</h3>
          <p>Set per-step or global timeouts (in seconds):</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">await agent({ llm, timeout: 60 })
  .then({ prompt: "Quick check", timeout: 5 })  // Override to 5s
  .then({ prompt: "Next step uses agent default (60s)" })
  .run();</code></pre>
          </div>

          <h3>Retry Strategies</h3>
          
          <h4>Immediate Retry (Default)</h4>
          <p>Retry immediately without waiting:</p>
          <div class="code-block">
            <pre><code class="language-typescript">await agent({ llm, retry: { retries: 3 } })
  .then({ prompt: "hello" })
  .run();</code></pre>
          </div>

          <h4>Delayed Retry</h4>
          <p>Wait a fixed duration between attempts:</p>
          <div class="code-block">
            <pre><code class="language-typescript">await agent({ llm, retry: { delay: 20, retries: 3 } })
  .then({ prompt: "unstable action" })
  .run();
// Waits 20s between each retry</code></pre>
          </div>

          <h4>Exponential Backoff</h4>
          <p>Progressively longer waits between retries:</p>
          <div class="code-block">
            <pre><code class="language-typescript">await agent({ llm, retry: { backoff: 2, retries: 4 } })
  .then({ prompt: "might fail" })
  .run();
// Waits: 1s, 2s, 4s, 8s between attempts</code></pre>
          </div>

          <h3>Per-Step Override</h3>
          <div class="code-block">
            <pre><code class="language-typescript">await agent({ llm, retry: { delay: 20 } })
  .then({ prompt: "override to immediate", retry: { delay: 0 } })
  .run();</code></pre>
          </div>

          <h3>Retry Semantics</h3>
          <ul>
            <li>Non-retryable errors (like <code>ValidationError</code>) abort immediately</li>
            <li>Retryable errors include: timeouts, 429, 5xx, network errors</li>
            <li>On retry exhaustion, the last error is thrown</li>
            <li>You cannot set both <code>delay</code> and <code>backoff</code></li>
          </ul>
        </section>

        <!-- Step Hooks -->
        <section id="hooks" class="doc-section">
          <h2>Step Hooks</h2>
          <p>Add <code>pre</code> and <code>post</code> hooks for fine-grained control over execution flow:</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">await agent({ llm })
  .then({
    prompt: "Analyze the user data",
    mcps: [analytics],
    pre: () => { console.log("Starting analysis..."); },
    post: () => { console.log("Analysis complete!"); }
  })
  .then({
    prompt: "Generate report",
    pre: () => { startTimer(); },
    post: () => { endTimer(); saveMetrics(); }
  })
  .run((step, stepIndex) => {
    console.log(`Step ${stepIndex + 1} finished`);
  });</code></pre>
          </div>

          <h3>Hook Execution Order</h3>
          <ol>
            <li><code>pre()</code> hook (before step execution)</li>
            <li>Step execution (LLM/MCP calls)</li>
            <li><code>post()</code> hook (after step completion)</li>
            <li><code>run()</code> callback (with step result and index)</li>
          </ol>

          <h3>Hook Characteristics</h3>
          <ul>
            <li>Hooks are <strong>synchronous functions</strong> (<code>() =&gt; void</code>)</li>
            <li>Hook errors are <strong>caught and logged</strong> but don't fail the step</li>
            <li>Hooks execute on <strong>every retry attempt</strong> (pre) or <strong>only on success</strong> (post)</li>
            <li>Hooks have access to <strong>closure variables</strong> for state management</li>
          </ul>

          <div class="info-box warning">
            <div class="info-icon">⚠️</div>
            <div>
              <strong>Note:</strong> Hook errors are caught and logged but do not fail the step. Pre-hooks execute on every retry attempt. Post-hooks execute only on successful completion.
            </div>
          </div>

          <h3>Use Cases</h3>
          <ul>
            <li>Performance monitoring and timing</li>
            <li>Logging and debugging</li>
            <li>State management</li>
            <li>Notifications and alerts</li>
            <li>Metrics collection</li>
          </ul>
        </section>

        <!-- Error Handling -->
        <section id="errors" class="doc-section">
          <h2>Error Handling</h2>
          <p>Volcano surfaces typed errors with rich metadata for easy debugging.</p>
          
          <h3>Error Types</h3>
          <table class="params-table">
            <thead>
              <tr>
                <th>Error Type</th>
                <th>Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><code>AgentConcurrencyError</code></td>
                <td>run() called twice on same instance</td>
              </tr>
              <tr>
                <td><code>TimeoutError</code></td>
                <td>Step exceeded timeout limit</td>
              </tr>
              <tr>
                <td><code>ValidationError</code></td>
                <td>Tool args failed schema validation</td>
              </tr>
              <tr>
                <td><code>RetryExhaustedError</code></td>
                <td>Final failure after all retries</td>
              </tr>
              <tr>
                <td><code>LLMError</code></td>
                <td>LLM provider error</td>
              </tr>
              <tr>
                <td><code>MCPToolError</code></td>
                <td>MCP tool execution error</td>
              </tr>
              <tr>
                <td><code>MCPConnectionError</code></td>
                <td>MCP connection error</td>
              </tr>
            </tbody>
          </table>

          <h3>Error Metadata</h3>
          <p>All Volcano errors include metadata for debugging:</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">try {
  await agent({ llm, retry: { backoff: 2, retries: 4 }, timeout: 30 })
    .then({ prompt: 'auto', mcps: [mcp('http://localhost:3211/mcp')] })
    .run();
} catch (err) {
  if (err && typeof err === 'object' && 'meta' in err) {
    const e = err as VolcanoError;
    
    console.error(e.name, e.message);
    console.error('Metadata:', {
      stepId: e.meta.stepId,        // 0-based step index
      provider: e.meta.provider,     // llm:openai or mcp:localhost
      requestId: e.meta.requestId,   // Upstream request ID
      retryable: e.meta.retryable    // Should retry?
    });
    
    if (e.meta?.retryable) {
      // Maybe enqueue for retry later
    }
  }
}</code></pre>
          </div>

          <h3>Metadata Fields</h3>
          <ul>
            <li><code>stepId</code>: 0-based index of the failing step</li>
            <li><code>provider</code>: <code>llm:&lt;id|model&gt;</code> or <code>mcp:&lt;host&gt;</code></li>
            <li><code>requestId</code>: Upstream provider request ID when available</li>
            <li><code>retryable</code>: Volcano's hint (true for 429/5xx/timeouts; false for validation/4xx)</li>
          </ul>
        </section>

        <!-- MCP Tools -->
        <section id="mcp-tools" class="doc-section">
          <h2>MCP Tools</h2>
          <p>The Model Context Protocol (MCP) enables AI agents to securely interact with external tools and data sources.</p>
          
          <h3>Automatic Tool Selection</h3>
          <p>Let the LLM choose which tools to call:</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">const weather = mcp("http://localhost:3000/mcp");
const notifications = mcp("http://localhost:4000/mcp");

await agent({ llm })
  .then({
    prompt: "Check SF weather and send me a notification.",
    mcps: [weather, notifications]
  })
  .run();</code></pre>
          </div>

          <h3>Explicit Tool Calling</h3>
          <p>Call specific tools directly:</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">const cafe = mcp("http://localhost:3000/mcp");

await agent({ llm })
  .then({ prompt: "Recommend a coffee for Ava from Naples" })
  .then({ 
    mcp: cafe, 
    tool: "order_item", 
    args: { item_id: "espresso" } 
  })
  .run();</code></pre>
          </div>

          <h3>Features</h3>
          <table class="params-table">
            <thead>
              <tr>
                <th>Feature</th>
                <th>Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Connection Pooling</td>
                <td>TCP sessions reused across steps, idle connections evicted</td>
              </tr>
              <tr>
                <td>Tool Discovery Cache</td>
                <td><code>listTools()</code> results cached with TTL, invalidated on failures</td>
              </tr>
              <tr>
                <td>JSON Schema Validation</td>
                <td>Arguments validated against schema before tool execution</td>
              </tr>
              <tr>
                <td>Automatic Retries</td>
                <td>Connection errors retry automatically with backoff</td>
              </tr>
            </tbody>
          </table>

          <h3>Configuration</h3>
          <p>Pool and cache settings (for advanced use):</p>
          
          <div class="code-block">
            <pre><code class="language-typescript">// Internal test helpers (not typically needed)
import { 
  __internal_setPoolConfig,
  __internal_setDiscoveryTtl,
  __internal_clearDiscoveryCache,
  __internal_forcePoolCleanup
} from "volcano-sdk";

// Set pool size and idle timeout
__internal_setPoolConfig(16, 30_000); // max 16 connections, 30s idle

// Set discovery cache TTL
__internal_setDiscoveryTtl(60_000); // 60s cache</code></pre>
          </div>

          <div class="info-box">
            <div class="info-icon">💡</div>
            <div>
              <strong>Note:</strong> MCP tools are automatically discovered and cached. Connection management and schema validation are handled by the SDK.
            </div>
          </div>
        </section>

      </div>

      <!-- Table of Contents (Right Sidebar) -->
      <aside class="toc">
        <div class="toc-header">On this page</div>
        <nav class="toc-nav" id="toc-nav">
          <!-- Dynamically populated by script.js -->
        </nav>
      </aside>
    </main>
  </div>

  <script src="script.js"></script>
</body>
</html>
